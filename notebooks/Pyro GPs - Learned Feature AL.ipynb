{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "import pyro.distributions as dist\n",
    "from models.networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_net = Simple()\n",
    "feature_net.load_state_dict(torch.load(\"cnn_75.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.CenterCrop(255),\n",
    "    transforms.Resize(100),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "voc_data = torchvision.datasets.Cityscapes('data', split=\"test\", mode=\"fine\", target_type=\"semantic\",\n",
    "                                           transform=transformations, target_transform=transformations)\n",
    "data_loader = torch.utils.data.DataLoader(voc_data,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(image, seg, gt):\n",
    "    feats = torch.squeeze(feature_net(torch.unsqueeze(image, dim=0), torch.unsqueeze(seg.view(-1, 100, 100), dim=0)).permute(0, 2, 3, 1))\n",
    "    x = feats.detach()\n",
    "    y = gt.detach()/gt.max()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_least_confident(X, y, cov, samples_seen):\n",
    "    lcs = np.argsort(cov.detach().numpy())\n",
    "    for lc_i in lcs:\n",
    "        i = lc_i // 100\n",
    "        j = lc_i % 100\n",
    "        if (i, j) not in samples_seen:\n",
    "            break\n",
    "    return (i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008677465468645096\n"
     ]
    }
   ],
   "source": [
    "input_dim = 75\n",
    "num_samples = 50\n",
    "num_steps = 10\n",
    "total = 0.0\n",
    "samples_seen = []\n",
    "cur_segs = []\n",
    "for i in [1]:\n",
    "    one, two = voc_data.__getitem__(i)\n",
    "    cur_seg = torch.zeros((100, 100))\n",
    "    X, y = get_features(one, cur_seg, two)\n",
    "    first_sample = (0, 0)\n",
    "    samples_seen.append(first_sample)\n",
    "    X_train = np.array([X[sample].numpy() for sample in samples_seen])\n",
    "    y_train = np.array([y[0, sample[0], sample[1]].numpy() for sample in samples_seen])\n",
    "    kernel = gp.kernels.RBF(input_dim=input_dim, variance=torch.tensor(1.),\n",
    "                            lengthscale=torch.tensor(10.))\n",
    "    gpr = gp.models.GPRegression(torch.from_numpy(X_train).float(), \n",
    "                                 torch.from_numpy(y_train).float(), kernel, noise=torch.tensor(1.))\n",
    "    optimizer = torch.optim.Adam(gpr.parameters(), lr=0.005)\n",
    "    loss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n",
    "    losses = []\n",
    "    for i in range(num_samples):\n",
    "        gpr.set_data(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float())\n",
    "        for j in range(num_steps):\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(gpr.model, gpr.guide)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        #print(j, loss.item())\n",
    "        mean, cov = gpr(X.view(-1, input_dim))\n",
    "        next_x = get_least_confident(X, y, cov.detach().float(), samples_seen)\n",
    "        #print(next_x)\n",
    "        samples_seen.append(next_x)\n",
    "        cur_segs.append(cur_seg.detach().numpy())\n",
    "        cur_seg[next_x[0], next_x[1]] = y[0, next_x[0], next_x[1]]\n",
    "        X, y = get_features(one, cur_seg, two)\n",
    "        X_train = np.array([X[sample].numpy() for sample in samples_seen])\n",
    "        y_train = np.array([y[0, sample[0], sample[1]].numpy() for sample in samples_seen])\n",
    "        #print(np.nonzero(cur_seg.detach().numpy()))\n",
    "    loss = np.mean((mean.view(-1, 100, 100).detach().numpy()-y.numpy())**2)\n",
    "    total += loss\n",
    "print(total/(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y.reshape(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cur_seg.reshape(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mean.detach().numpy().reshape(100, 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
